# -*- coding: utf-8 -*-
"""sigmoid, Relu, tanh.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/13eA1jAchhBT4ml6yyaunbnJJbmCVvhcQ
"""

import numpy as np
a = [0.1, 1.5, 15.0, 2.0, 3.0]

def softmax(a):
 exp_a = np.exp(a)
 sum_exp_a = np.sum(exp_a)
 y = exp_a / sum_exp_a
# std_y = np.std(y)
 return y

print(softmax(a))



import numpy as np
a = [0.1, 1.5, 15.0, 2.0, 3.0]

def softmax(a):
 sum_a = np.sum(a)
 y = a / sum_a
 return y

print(softmax(a))

"""#numpy.exp(x) :  e の x 乗を返します
#np.sum(x)      : 配列の要素の和

expをつけることによって、通知が全く違ってくる
"""

import numpy as np
import matplotlib.pyplot as plt

n_cols = 4
n_rows = 2

plt.figure(figsize=(20, 8))
x = np.arange(-5, 5, 0.1)

# Sigmoid

y=1.0 / (1.0 + np.exp(-x))
plt.subplot(n_rows,n_cols,1)
plt.title('Sigmoid')
plt.plot(x, y)

import numpy as np
import matplotlib.pyplot as plt

n_cols = 4
n_rows = 2

plt.figure(figsize=(20, 8))
x = np.arange(-5, 5, 0.1)

# Softplus

y=np.log(1 + np.exp(x))
plt.subplot(n_rows,n_cols,1)
plt.title('Softplus')
plt.plot(x, y)

import numpy as np
import matplotlib.pyplot as plt

def step_function(x):
  return np.array(x > 0, dtype=np.int)

x = np.arange(-5, 5, 0.1)
y=step_function(x)
plt.plot(x, y)
plt.ylim(-0.1, 1.1)
plt.title('Step Function')
plt.show

import numpy as np
import matplotlib.pyplot as plt

def relu(x):
  return np.maximum(0,x)

x = np.arange(-5, 5, 0.1)
y=relu(x)
plt.plot(x, y)
plt.ylim(-1, 4.0)
plt.title('ReLU')
plt.show

# https://gcbgarden.com/2017/12/18/tanh-function/
import numpy as np
import matplotlib.pyplot as plt

def tanh(x):
    y = (np.exp(x) - np.exp(-x)) / (np.exp(x) + np.exp(-x))
    return y

#-8から8までの値0.1刻みで生成
X = np.arange(-8, 8, 0.1)
#Xの値をtanh関数に渡す
Y = tanh(X)
#プロット
plt.plot(X,Y)
#タイトル表示
plt.title("tanh")
#グリッド線
plt.grid()
#グラフ出力
plt.show()