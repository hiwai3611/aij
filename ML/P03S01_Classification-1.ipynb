{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification-1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2値分類用のサンプルデータであるBreast Cancerを読み込みます。<br>特徴量が全て数値データで欠損値もないキレイなサンプルデータです。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "X shape: (569,30)\n",
      "y shape: (569,1)\n",
      "--------------------------------------------------\n",
      "y\n",
      "0    212\n",
      "1    357\n",
      "dtype: int64\n",
      "--------------------------------------------------\n",
      "y=0 means Marignant(悪性),y=1 means Benign(良性):\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <th>...</th>\n",
       "      <th>worst texture</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.07871</td>\n",
       "      <td>...</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.05667</td>\n",
       "      <td>...</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.05999</td>\n",
       "      <td>...</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>0.09744</td>\n",
       "      <td>...</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>0.05883</td>\n",
       "      <td>...</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
       "0        17.99         10.38          122.80     1001.0          0.11840   \n",
       "1        20.57         17.77          132.90     1326.0          0.08474   \n",
       "2        19.69         21.25          130.00     1203.0          0.10960   \n",
       "3        11.42         20.38           77.58      386.1          0.14250   \n",
       "4        20.29         14.34          135.10     1297.0          0.10030   \n",
       "\n",
       "   mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
       "0           0.27760          0.3001              0.14710         0.2419   \n",
       "1           0.07864          0.0869              0.07017         0.1812   \n",
       "2           0.15990          0.1974              0.12790         0.2069   \n",
       "3           0.28390          0.2414              0.10520         0.2597   \n",
       "4           0.13280          0.1980              0.10430         0.1809   \n",
       "\n",
       "   mean fractal dimension ...  worst texture  worst perimeter  worst area  \\\n",
       "0                 0.07871 ...          17.33           184.60      2019.0   \n",
       "1                 0.05667 ...          23.41           158.80      1956.0   \n",
       "2                 0.05999 ...          25.53           152.50      1709.0   \n",
       "3                 0.09744 ...          26.50            98.87       567.7   \n",
       "4                 0.05883 ...          16.67           152.20      1575.0   \n",
       "\n",
       "   worst smoothness  worst compactness  worst concavity  worst concave points  \\\n",
       "0            0.1622             0.6656           0.7119                0.2654   \n",
       "1            0.1238             0.1866           0.2416                0.1860   \n",
       "2            0.1444             0.4245           0.4504                0.2430   \n",
       "3            0.2098             0.8663           0.6869                0.2575   \n",
       "4            0.1374             0.2050           0.4000                0.1625   \n",
       "\n",
       "   worst symmetry  worst fractal dimension  y  \n",
       "0          0.4601                  0.11890  0  \n",
       "1          0.2750                  0.08902  0  \n",
       "2          0.3613                  0.08758  0  \n",
       "3          0.6638                  0.17300  0  \n",
       "4          0.2364                  0.07678  0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load and return the breast cancer wisconsin dataset (classification).\n",
    "# The breast cancer dataset is a classic and very easy binary classification dataset.\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "\n",
    "# Set dataframe\n",
    "dataset = load_breast_cancer()\n",
    "X = pd.DataFrame(dataset.data, columns=dataset.feature_names)\n",
    "y = pd.DataFrame(dataset.target, columns=['y'])\n",
    "\n",
    "# check the shape\n",
    "print('--------------------------------------------------')\n",
    "print('X shape: (%i,%i)' %X.shape)\n",
    "print('y shape: (%i,%i)' %y.shape)\n",
    "print('--------------------------------------------------')\n",
    "print(y.groupby('y').size())\n",
    "print('--------------------------------------------------')\n",
    "print('y=0 means Marignant(悪性),y=1 means Benign(良性):')\n",
    "print('--------------------------------------------------')\n",
    "X.join(y).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "k近傍法とロジスティック回帰の呼び出し方を学びましょう。KNNはneighborsというクラスから呼び出しています。ロジスティック回帰は重みベクトルと特徴量の一次線形結合をベースとしたアルゴリズムなので、線形モデルから呼び出せます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "回帰でも学びましたが、機械学習のアルゴリズムは特徴量ベクトルを標準化するのが普通です。実装は標準化処理とモデル学習（重みの最適化）のプロセスをひとまとめに記述できるパイプラインが便利なため呼び出します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "回帰モデルの評価にはR2スコア等がありました。分類モデルの評価の場合、最もわかりやすいものが正解率（Accuracy）です。正解率は予測対象データ（スコアリングデータ）の全件をNとした時、正例を正しく正例と分類できた数TP、負例を正しく負例と分類できた数TFとすると、 以下の数式で表せます。<br><center>Accuracy = (TP + TF) / N</center><br>つまり、正例・負例を問わず正しく分類されたサンプル数の割合です。sklearnでは正解データ（正解ベクトル）と予測データ（予測ベクトル）を与えると、Accuracyを計算してくれる関数が存在します。それを以下で呼び込みましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 分類モデルの評価指標（計算ライブラリ）の読み込み\n",
    "# sklearn.metrics.accuracy_score(y_true, y_pred, normalize=True, sample_weight=None)\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "以下コードの各行の役割を理解できていることを確認して下さい。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hiroa\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:23: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "C:\\Users\\hiroa\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:24: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n"
     ]
    }
   ],
   "source": [
    "# import basice apis\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# import Sample Data to learn models\n",
    "dataset = load_breast_cancer()\n",
    "X = pd.DataFrame(dataset.data, columns=dataset.feature_names)\n",
    "y = pd.DataFrame(dataset.target, columns=['y'])\n",
    "\n",
    "# Holdout\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,\n",
    "                                                 y,\n",
    "                                                 test_size=0.20,\n",
    "                                                 random_state=1)\n",
    "# 整形\n",
    "y_train = y_train.as_matrix().ravel()\n",
    "y_test = y_test.as_matrix().ravel()\n",
    "\n",
    "# set pipelines for two different algorithms\n",
    "pipe_knn_5 = Pipeline([('scl',StandardScaler()),\n",
    "                       ('est',KNeighborsClassifier())])\n",
    "pipe_knn_50 = Pipeline([('scl',StandardScaler()),\n",
    "                        ('est',KNeighborsClassifier(n_neighbors=50))])\n",
    "pipe_knn_400 = Pipeline([('scl',StandardScaler()),\n",
    "                        ('est',KNeighborsClassifier(n_neighbors=400))])\n",
    "\n",
    "pipe_logistic = Pipeline([('scl',StandardScaler()),\n",
    "                          ('est',LogisticRegression(random_state=1))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "knn_5はデフォルトのK近傍法のパフォーマンス確認、pipe_knn_50は近傍数を増やしたときの性能確認用です。Kを増やすことで予測性能（正解率）がどのように変化するか考えてみましょう。pipe_logisticはロジスティック回帰の性能確認用です。kNNよりは良いだろうというのが通常の期待です。それでは各パイプラインを学習(fit)させましょう。正常終了すれば終了です。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('scl', StandardScaler(copy=True, with_mean=True, with_std=True)), ('est', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=1, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False))])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# optimize the parameters of each algorithms\n",
    "pipe_knn_5.fit(X_train,y_train)\n",
    "pipe_knn_50.fit(X_train,y_train)\n",
    "pipe_knn_400.fit(X_train,y_train)\n",
    "pipe_logistic.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "最後に、３つのパイプラインの分類器としての性能（正解率）を比較します。<br>まずpipelineのpredictの出力ベクトルを見て下さい。<br>y_pred in {0,1}で予測ラベルが付与されていることがわかります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, 1, 1, 1, 1, 0, 0, 1])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### pipe_logistic.predict(X_train)[:10]\n",
    "pipe_logistic.predict(X_train)[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "今回は使いませんが、実務では予測ラベルの他に各クラスに分類される予測確率をよく使います。<b>予測確率を出力させたい場合はpredictをpredic_probaに変更するだけです。</b>最初の列はy=0と分類される予測確率、2番目の列はy=1と分類される予測確率です。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9.99441634e-01, 5.58366357e-04],\n",
       "       [9.99962234e-01, 3.77655428e-05],\n",
       "       [1.12299304e-06, 9.99998877e-01],\n",
       "       [4.10316174e-04, 9.99589684e-01],\n",
       "       [1.83025794e-04, 9.99816974e-01],\n",
       "       [7.88575120e-03, 9.92114249e-01],\n",
       "       [6.74588243e-02, 9.32541176e-01],\n",
       "       [9.99956558e-01, 4.34422063e-05],\n",
       "       [9.99999212e-01, 7.88384042e-07],\n",
       "       [2.32654465e-02, 9.76734554e-01]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe_logistic.predict_proba(X_train)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "正例\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[5.58366357e-04],\n",
       "       [3.77655428e-05],\n",
       "       [9.99998877e-01],\n",
       "       [9.99589684e-01],\n",
       "       [9.99816974e-01],\n",
       "       [9.92114249e-01],\n",
       "       [9.32541176e-01],\n",
       "       [4.34422063e-05],\n",
       "       [7.88384042e-07],\n",
       "       [9.76734554e-01]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"正例\")\n",
    "pipe_logistic.predict_proba(X_train)[:10, [1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "負例\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[9.99441634e-01],\n",
       "       [9.99962234e-01],\n",
       "       [1.12299304e-06],\n",
       "       [4.10316174e-04],\n",
       "       [1.83025794e-04],\n",
       "       [7.88575120e-03],\n",
       "       [6.74588243e-02],\n",
       "       [9.99956558e-01],\n",
       "       [9.99999212e-01],\n",
       "       [2.32654465e-02]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"負例\")\n",
    "pipe_logistic.predict_proba(X_train)[:10, [0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "accuracy_scoreは第一引数に正解ラベル、第二引数に予測ラベル（確率ではない）を指定します。<br>今回はpredictで予測ラベルを与えましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN(5)_Train:0.982\n",
      "KNN(5)_Test:0.956\n",
      "KNN(50)_Train:0.952\n",
      "KNN(50)_Test:0.947\n",
      "KNN(400)_Train:0.626\n",
      "KNN(400)_Test:0.632\n",
      "Logistic_Train:0.991\n",
      "Logistic_Test:0.982\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "print('KNN(5)_Train:%.3f'% accuracy_score(y_train,\n",
    "                                          pipe_knn_5.predict(X_train)))\n",
    "print('KNN(5)_Test:%.3f' % accuracy_score(y_test,\n",
    "                                          pipe_knn_5.predict(X_test)))\n",
    "\n",
    "print('KNN(50)_Train:%.3f'% accuracy_score(y_train,\n",
    "                                           pipe_knn_50.predict(X_train)))\n",
    "print('KNN(50)_Test:%.3f' % accuracy_score(y_test,\n",
    "                                           pipe_knn_50.predict(X_test)))\n",
    "\n",
    "print('KNN(400)_Train:%.3f'% accuracy_score(y_train,\n",
    "                                           pipe_knn_400.predict(X_train)))\n",
    "print('KNN(400)_Test:%.3f' % accuracy_score(y_test,\n",
    "                                           pipe_knn_400.predict(X_test)))\n",
    "\n",
    "print('Logistic_Train:%.3f'% accuracy_score(y_train,\n",
    "                                            pipe_logistic.predict(X_train)))\n",
    "print('Logistic_Test:%.3f' % accuracy_score(y_test,\n",
    "                                            pipe_logistic.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "k近傍法のkを5から50に増やしましたが、性能が落ちてしまいました。多くのデータを見過ぎて平均値予測に近づき過ぎてしまったようです。予測値が無難過ぎてTrainスコアとTestスコアが近いのも特徴です。ロジスティック回帰は、k近傍法より3pt（0.956 to 0.982）程度、改善することを確認できました。ただし、どのように改善するか（しないか）はデータ次第ですので、代表的なアルゴリズムをいつでも試せる準備をしておくことが、プロジェクト進行において大切です。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
